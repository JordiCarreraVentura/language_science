{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a28a45-1759-44aa-966a-c77bec19b6de",
   "metadata": {},
   "source": [
    "# Ranking metrics\n",
    "\n",
    "1. [Online metrics](#online-metrics)\n",
    "   1. [Hit Ratio](#hit-ratio)\n",
    "2. [Offline metrics](#offline-metrics)\n",
    "   1. [Reciprocal Rank and Mean Reciprocal Rank](#reciprocal-rank-and-mean-reciprocal-rank)\n",
    "   2. [Mean Average Precision](#mean-average-precision-map)\n",
    "3. [Examples](#examples)\n",
    "4. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb2e35-e938-47e2-b7c2-a836211ef47f",
   "metadata": {},
   "source": [
    "## Online metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330f9d8-9903-478e-aa4a-9e7846613866",
   "metadata": {},
   "source": [
    "### Hit Ratio\n",
    "\n",
    "[Source 1](#reference_1)\n",
    "\n",
    "> the fraction of users for which the correct answer is included in the recommendation list of length $L$.\n",
    "\n",
    "$D = \\text{the superset containing every set of recommendations }d\\text{ served to a user, such that }|d| = L$\n",
    "\n",
    "$y = \\text{the correct answer}$\n",
    "\n",
    "$$HR_L = \\frac{|d: d \\in D \\land y \\in d|}{|D|}$$\n",
    "\n",
    "**NOTE**: $L$ is a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d35c4a-c719-46b6-a51e-1e508b8a1b8d",
   "metadata": {},
   "source": [
    "## Offline metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec4d19-5199-40ab-ad6f-81e1c7a3f509",
   "metadata": {},
   "source": [
    "### Reciprocal Rank and Mean Reciprocal Rank\n",
    "\n",
    "[Source 1](#reference_1), [Back to top](#ranking-metrics)\n",
    "\n",
    "$D = \\text{the superset containing every ranked set of recommendations }d\\text{ served to a user, such that }|d| = L$\n",
    "\n",
    "$$RR(d) = \\sum\\limits_{i: 1 ≤ i ≤ L} \\frac{relevance_i}{rank_i}$$\n",
    "\n",
    "$$MRR(D) = \\frac{ \\sum\\limits_{i = 1}^{|D|} RR(D_i) }{|D|} $$\n",
    "\n",
    "**NOTE**: _one could argue that hit ratio is actually a special case of MRR in which RR(d) is binary, as it becomes 1 if there is a relevant item in the list, 0 otherwise._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80531ea4-5dfb-431d-b8d8-499e8fc29fe2",
   "metadata": {},
   "source": [
    "### Mean Average Precision (MAP)\n",
    "\n",
    "[Source 1](#reference_1), [Back to top](#ranking-metrics)\n",
    "\n",
    "$K = \\text{the maximum number of top elements we want to consider}$\n",
    "\n",
    "$k = \\text{the number of top elements we want to consider to calculate metrics such that } 1 ≤ k ≤ K$\n",
    "\n",
    "$D = \\text{the superset containing every ranked list of recommendations }d\\text{ served to a user, such that }|d| = k$\n",
    "\n",
    "$$AP(D_i) = \\sum\\limits_{k = 1}^{K} \\text{Precision@}k(D_i) \\times RelevanceMask_i$$\n",
    "\n",
    "$$MAP(D) = \\frac{\\sum\\limits_{i = 1}^{|D|} AP(D_i)}{|D|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0b09d-df0e-4cd9-b8a2-666b875b1bff",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain\n",
    "\n",
    "[Source](https://towardsdatascience.com/normalized-discounted-cumulative-gain-ndcg-the-ultimate-ranking-metric-437b03529f75), [Back to top](#ranking-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d995d-a7ad-4c47-bc0a-425557a90a18",
   "metadata": {},
   "source": [
    "#### Cumulative Gain (CG)\n",
    "\n",
    "> The **.cumulative gain** is the sum of the relevance scores of items in the list.\n",
    "\n",
    "$$CG = \\sum\\limits_{i = 1}^{K} \\text{relevance}(K_i)$$\n",
    "\n",
    "> If you’re computing NDCG@10, CG@10 will be 12 for both lists.\n",
    "> \n",
    "> If you’re computing NDCG@5, CG@5 for Model A is 7, and for Model B is 10\n",
    "\n",
    "#### Discount Factor (DF)\n",
    "\n",
    "> The **discount factor** involves using a logarithmic discounting factor to perform a weighted sum of the relevance scores of items in the list. The discounting factor is weighted based on the item’s position in the list.\n",
    "\n",
    "It is based on the same intuition as the reciprocal rank but it is smoothed by the use of the logarithm: for the item in the 10th rank, instead of computing the score as $1 / 10$ (the reciprocal rank), we calculate it as $1 / log(10)$, which means that the denominator is smaller and the result, therfore, higher. So, while we still penalize higher ranks, we are not penalizing them as much as the reciprocal rank, probably reflecting the intuition that _there is not a single correct answer_, as well as smoothing out/squeezing together potential anomalies in the scoring function.\n",
    "\n",
    "$$DF = \\frac{1}{log_2(1 + i)}$$\n",
    "\n",
    "\n",
    "#### Normalization constant\n",
    "\n",
    "> We want to normalize the model’s DCG by dividing it by the DCG obtained by an ideal ranker.\n",
    "> \n",
    "> An ideal ranks the items in descending order of relevance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa64620-0597-451b-9634-cf444b532272",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe0a5285-00d4-43d6-955d-61f9ac585e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import random\n",
    "from typing import Iterable, Union\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88926282-fd81-494c-bdb7-acc1cb7cc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_gain(relevances: pd.Series, k: int) -> float:\n",
    "    if not isinstance(relevances, pd.Series):\n",
    "        raise TypeError(type(relevances), pd.Series)\n",
    "    return relevances.head(k).sum()\n",
    "\n",
    "def discount_factor(iterable: pd.Series) -> Iterable[float]:\n",
    "    if not isinstance(iterable, pd.Series):\n",
    "        raise TypeError(type(iterable), pd.Series)\n",
    "    discount_factors = []\n",
    "    for idx, item in enumerate(iterable):\n",
    "        discount_factors.append(1 / log(1 + (idx + 1)))\n",
    "    return discount_factors\n",
    "\n",
    "def discounted_cumulative_gain(relevances: pd.Series, k: int) -> float:\n",
    "    if not isinstance(relevances, pd.Series):\n",
    "        raise TypeError(type(relevances), pd.Series)\n",
    "    discounted_cumulative_gain = 0\n",
    "    for idx, item in enumerate(relevances.head(k)):\n",
    "        discounted_cumulative_gain += (item / log(1 + (idx + 1)))\n",
    "    return discounted_cumulative_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7d82b08-91da-48e6-97bc-5f46243e854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_by_action = {\n",
    "    \"Viewed\": 0,\n",
    "    \"Clicked\": 1,\n",
    "    \"Shared\": 2,\n",
    "    \"AddedToCart\": 3,\n",
    "    \"Ordered\": 4,\n",
    "}\n",
    "\n",
    "actions = list(relevance_by_action.keys())\n",
    "item_ids = list(range(10))\n",
    "\n",
    "event_items = [random.choice(item_ids) for _ in range(100)]\n",
    "event_actions = [random.choice(actions) for _ in event_items]\n",
    "\n",
    "events = []\n",
    "for item, action in zip(event_items, event_actions):\n",
    "    event = (\n",
    "        item,\n",
    "        action,\n",
    "        relevance_by_action[action],\n",
    "        round(((5 / (relevance_by_action[action] + 1)) / 10) if random.random() >= 0.2 else random.uniform(0, 1.0), 2),\n",
    "        round(random.uniform(0, 1.0), 2)\n",
    "    )\n",
    "    events.append(event)\n",
    "\n",
    "df = pd.DataFrame(events, columns=[\"item\", \"action\", \"relevance\", \"model_a\", \"model_b\"])\n",
    "df_model_a = df.copy().drop(\"model_b\", axis=1).sort_values(\"model_a\", ascending=True)\n",
    "df_model_b = df.copy().drop(\"model_a\", axis=1).sort_values(\"model_b\", ascending=True)\n",
    "df_ideal = df.copy().drop([\"model_a\", \"model_b\"], axis=1).sort_values(\"relevance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b711ea13-8af4-492f-8b66-38c077d660a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>action</th>\n",
       "      <th>relevance</th>\n",
       "      <th>model_a</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.442695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.910239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.621335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.558111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item   action  relevance  model_a    factor\n",
       "41     1  Ordered          4     0.06  1.442695\n",
       "9      0  Ordered          4     0.10  0.910239\n",
       "17     9  Ordered          4     0.10  0.721348\n",
       "15     2  Ordered          4     0.10  0.621335\n",
       "79     6  Ordered          4     0.10  0.558111"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_a[\"factor\"] = discount_factor(df_model_a[\"item\"])\n",
    "df_model_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bbc0fb8-cd21-4b4b-b196-914687638e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>action</th>\n",
       "      <th>relevance</th>\n",
       "      <th>model_b</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>AddedToCart</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.442695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Clicked</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.910239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8</td>\n",
       "      <td>Viewed</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.621335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.558111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item       action  relevance  model_b    factor\n",
       "66     0  AddedToCart          3     0.02  1.442695\n",
       "18     1      Clicked          1     0.02  0.910239\n",
       "90     3       Shared          2     0.04  0.721348\n",
       "96     8       Viewed          0     0.05  0.621335\n",
       "17     9      Ordered          4     0.06  0.558111"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_b[\"factor\"] = discount_factor(df_model_b[\"item\"])\n",
    "df_model_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9d4f324-346f-4655-b07a-ee5516a110b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 191 191\n",
      "40 24 40\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_gain(df_model_a.relevance, 10000), cumulative_gain(df_model_b.relevance, 10000), cumulative_gain(df_ideal.relevance, 10000))\n",
    "print(cumulative_gain(df_model_a.relevance, 10), cumulative_gain(df_model_b.relevance, 10), cumulative_gain(df_ideal.relevance, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8dd5227b-e746-492a-b361-ad2dd7027374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.12476793202073 57.920281164326546 70.50809485793498\n",
      "26.21988210017919 15.412238716986126 26.21988210017919\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    discounted_cumulative_gain(df_model_a.relevance, 10000),\n",
    "    discounted_cumulative_gain(df_model_b.relevance, 10000),\n",
    "    discounted_cumulative_gain(df_ideal.relevance, 10000)\n",
    ")\n",
    "print(\n",
    "    discounted_cumulative_gain(df_model_a.relevance, 10),\n",
    "    discounted_cumulative_gain(df_model_b.relevance, 10),\n",
    "    discounted_cumulative_gain(df_ideal.relevance, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28f3e402-e521-4600-bf32-6c0e13d2651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>action</th>\n",
       "      <th>relevance</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>1.442695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>8</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.621335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>Ordered</td>\n",
       "      <td>4</td>\n",
       "      <td>0.558111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item   action  relevance    factor\n",
       "45     9  Ordered          4  1.442695\n",
       "79     6  Ordered          4  0.910239\n",
       "48     3  Ordered          4  0.721348\n",
       "67     8  Ordered          4  0.621335\n",
       "69     6  Ordered          4  0.558111"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ideal[\"factor\"] = discount_factor(df_ideal[\"item\"])\n",
    "df_ideal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2fb03f-bab8-4b4f-b04c-e887fbbe6d4a",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "[Back to top](#ranking-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea562f1c-58af-4128-a29b-93d13db9fc62",
   "metadata": {},
   "source": [
    "### MAP @ k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a09e53a1-37bd-4460-9bc4-1b7c1bb1b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 6, 4, 7, 2, 9, 8, 1, 3]\n",
      "[7, 6, 4, 2, 9, 1, 3, 0, 5, 8]\n",
      "{5: 1, 0: 1, 6: 1, 4: 1, 7: 1, 2: 0, 9: 0, 8: 0, 1: 0, 3: 0}\n",
      "\n",
      "[4, 8, 6, 5, 3, 0, 2, 9, 1, 7]\n",
      "[4, 8, 6, 5, 3, 0, 2, 9, 1, 7]\n",
      "{4: 1, 8: 1, 6: 1, 5: 1, 3: 1, 0: 0, 2: 0, 9: 0, 1: 0, 7: 0}\n",
      "\n",
      "[9, 4, 3, 5, 8, 7, 2, 0, 6, 1]\n",
      "[9, 4, 3, 5, 8, 7, 2, 0, 6, 1]\n",
      "{9: 1, 4: 1, 3: 1, 5: 1, 8: 1, 7: 0, 2: 0, 0: 0, 6: 0, 1: 0}\n",
      "\n",
      "[2, 5, 9, 1, 3, 0, 8, 6, 7, 4]\n",
      "[2, 5, 9, 1, 3, 0, 8, 6, 7, 4]\n",
      "{2: 1, 5: 1, 9: 1, 1: 1, 3: 1, 0: 0, 8: 0, 6: 0, 7: 0, 4: 0}\n",
      "\n",
      "[2, 6, 3, 1, 9, 4, 5, 8, 0, 7]\n",
      "[2, 6, 3, 1, 9, 4, 5, 8, 0, 7]\n",
      "{2: 1, 6: 1, 3: 1, 1: 1, 9: 1, 4: 0, 5: 0, 8: 0, 0: 0, 7: 0}\n",
      "\n",
      "[0, 3, 1, 5, 7, 2, 6, 4, 9, 8]\n",
      "[5, 7, 9, 4, 8, 0, 1, 3, 6, 2]\n",
      "{0: 1, 3: 1, 1: 1, 5: 1, 7: 1, 2: 0, 6: 0, 4: 0, 9: 0, 8: 0}\n",
      "\n",
      "[0, 1, 3, 5, 2, 4, 7, 8, 6, 9]\n",
      "[0, 2, 4, 5, 7, 6, 8, 1, 3, 9]\n",
      "{0: 1, 1: 1, 3: 1, 5: 1, 2: 1, 4: 0, 7: 0, 8: 0, 6: 0, 9: 0}\n",
      "\n",
      "[2, 5, 1, 4, 9, 7, 3, 6, 8, 0]\n",
      "[2, 5, 1, 4, 9, 7, 3, 6, 8, 0]\n",
      "{2: 1, 5: 1, 1: 1, 4: 1, 9: 1, 7: 0, 3: 0, 6: 0, 8: 0, 0: 0}\n",
      "\n",
      "[7, 5, 8, 1, 4, 6, 9, 3, 0, 2]\n",
      "[1, 5, 0, 2, 7, 4, 3, 6, 8, 9]\n",
      "{7: 1, 5: 1, 8: 1, 1: 1, 4: 1, 6: 0, 9: 0, 3: 0, 0: 0, 2: 0}\n",
      "\n",
      "[1, 9, 2, 3, 8, 4, 0, 5, 7, 6]\n",
      "[1, 9, 2, 3, 8, 4, 0, 5, 7, 6]\n",
      "{1: 1, 9: 1, 2: 1, 3: 1, 8: 1, 4: 0, 0: 0, 5: 0, 7: 0, 6: 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "movies = list(range(10))\n",
    "n_users = 10\n",
    "n_relevant = 5\n",
    "\n",
    "get_preferences = lambda x: random.sample(movies, len(movies))\n",
    "\n",
    "movie_preferences = [\n",
    "    get_preferences(u)\n",
    "    for u in range(n_users)\n",
    "]\n",
    "\n",
    "relevance_masks = []\n",
    "for mvps in movie_preferences:\n",
    "    relevance_mask = dict([])\n",
    "    for idx, mvp in enumerate(mvps):\n",
    "        if idx < n_relevant:\n",
    "            relevance_mask[mvp] = 1\n",
    "        else:\n",
    "            relevance_mask[mvp] = 0\n",
    "    relevance_masks.append(relevance_mask)\n",
    "\n",
    "accuracy = 0.8\n",
    "movie_recommendations = [\n",
    "    preferences if random.random() < accuracy\n",
    "    else random.sample(preferences, len(preferences))\n",
    "    for preferences in movie_preferences\n",
    "]\n",
    "\n",
    "for rm, mv, mr in zip(relevance_masks, movie_preferences, movie_recommendations):\n",
    "    print(mv)\n",
    "    print(mr)\n",
    "    print(rm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da63339f-cfe1-4a7f-97e0-76be9dc705de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_at_k(denom, y_true, y_pred, k=2, relevance_masks=[], rounding=4):\n",
    "    tp = 0\n",
    "    p = 0\n",
    "    t = 0\n",
    "    if relevance_masks:\n",
    "        for preferences, recommendations, relevance_mask in zip(y_true, y_pred, relevance_masks):\n",
    "            expected = {mv for mv in preferences[:k] if relevance_mask[mv]}\n",
    "            predicted = {mv for mv in recommendations[:k] if relevance_mask[mv]}\n",
    "            true_positives = expected.intersection(predicted)\n",
    "            tp += len(true_positives)\n",
    "            p += k\n",
    "            t += sum(relevance_mask.values())\n",
    "    else:\n",
    "        for preferences, recommendations in zip(y_true, y_pred):\n",
    "            expected = {mv for mv in preferences[:k]}\n",
    "            predicted = {mv for mv in recommendations[:k]}\n",
    "            true_positives = expected.intersection(predicted)\n",
    "            tp += len(true_positives)\n",
    "            p += k\n",
    "            t += len(expected)\n",
    "    return round(tp / p if denom == 'precision' else tp / t, rounding)\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=2, relevance_masks=[], rounding=4):\n",
    "   return metric_at_k('precision', y_true, y_pred, k=k, relevance_masks=relevance_masks, rounding=rounding)\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=2, relevance_masks=[], rounding=4):\n",
    "   return metric_at_k('recall', y_true, y_pred, k=k, relevance_masks=relevance_masks, rounding=rounding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1d44e62-e31b-4df4-be29-e0a0c473ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n",
      "0.775\n",
      "0.62\n"
     ]
    }
   ],
   "source": [
    "print(precision_at_k(movie_preferences, movie_recommendations, 4))\n",
    "print(recall_at_k(movie_preferences, movie_recommendations, 4))\n",
    "print(recall_at_k(movie_preferences, movie_recommendations, 4, relevance_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9362e-d31b-4e3a-a3e0-a495e723782a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Back to top](#ranking-metrics)\n",
    "\n",
    "1. <a id=\"reference_1\"></a> [Ranking Evaluation Metrics for Recommender Systems](https://towardsdatascience.com/ranking-evaluation-metrics-for-recommender-systems-263d0a66ef54)\n",
    "2. <a id=\"reference_2\"></a>[Demystifying NDCG](https://towardsdatascience.com/demystifying-ndcg-bee3be58cfe0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
